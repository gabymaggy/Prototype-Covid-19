{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\Fer\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Fer\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Fer\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Fer\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Fer\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Fer\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\Fer\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Fer\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Fer\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Fer\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Fer\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Fer\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (16, 9)\n",
    "plt.style.use('fast')\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Activation,Flatten\n",
    "from sklearn.preprocessing import MinMaxScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fecha\n",
       "2020-03-24     39\n",
       "2020-03-25     33\n",
       "2020-03-26     42\n",
       "2020-03-27     60\n",
       "2020-03-28     78\n",
       "             ... \n",
       "2021-01-07    352\n",
       "2021-02-07    362\n",
       "2021-03-07    380\n",
       "2021-04-07    378\n",
       "2021-05-07    395\n",
       "Name: intubados, Length: 469, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intubados = pd.read_csv(\"intubados.csv\", parse_dates=[0], header=None,index_col=0, squeeze=True,names=['fecha','intubados'])\n",
    "intubados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "283\n",
      "186\n"
     ]
    }
   ],
   "source": [
    "#Contar los intubados por a√±o\n",
    "print(len(intubados['2020']))\n",
    "print(len(intubados['2021']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fecha\n",
       "2020-01-31     981.888889\n",
       "2020-02-29     972.444444\n",
       "2020-03-31     545.705882\n",
       "2020-04-30     798.074074\n",
       "2020-05-31    1269.392857\n",
       "2020-06-30    1180.185185\n",
       "2020-07-31    1063.750000\n",
       "2020-08-31     942.535714\n",
       "2020-09-30     912.703704\n",
       "2020-10-31     934.142857\n",
       "2020-11-30    1066.629630\n",
       "2020-12-31    1534.785714\n",
       "2021-01-31    2052.807692\n",
       "2021-02-28    1586.695652\n",
       "2021-03-31    1272.500000\n",
       "2021-04-30     941.960000\n",
       "2021-05-31     609.269231\n",
       "2021-06-30     547.958333\n",
       "2021-07-31    1301.833333\n",
       "2021-08-31    1280.833333\n",
       "2021-09-30    1273.500000\n",
       "2021-10-31    1268.333333\n",
       "2021-11-30    1269.333333\n",
       "2021-12-31    1252.666667\n",
       "Freq: M, Name: intubados, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Promedio mensual\n",
    "meses =intubados.resample('M').mean()\n",
    "meses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var1(t-7)</th>\n",
       "      <th>var1(t-6)</th>\n",
       "      <th>var1(t-5)</th>\n",
       "      <th>var1(t-4)</th>\n",
       "      <th>var1(t-3)</th>\n",
       "      <th>var1(t-2)</th>\n",
       "      <th>var1(t-1)</th>\n",
       "      <th>var1(t)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.994956</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.992434</td>\n",
       "      <td>-0.977301</td>\n",
       "      <td>-0.962169</td>\n",
       "      <td>-0.957125</td>\n",
       "      <td>-0.936108</td>\n",
       "      <td>-0.925179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.992434</td>\n",
       "      <td>-0.977301</td>\n",
       "      <td>-0.962169</td>\n",
       "      <td>-0.957125</td>\n",
       "      <td>-0.936108</td>\n",
       "      <td>-0.925179</td>\n",
       "      <td>-0.915931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.992434</td>\n",
       "      <td>-0.977301</td>\n",
       "      <td>-0.962169</td>\n",
       "      <td>-0.957125</td>\n",
       "      <td>-0.936108</td>\n",
       "      <td>-0.925179</td>\n",
       "      <td>-0.915931</td>\n",
       "      <td>-0.907524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.977301</td>\n",
       "      <td>-0.962169</td>\n",
       "      <td>-0.957125</td>\n",
       "      <td>-0.936108</td>\n",
       "      <td>-0.925179</td>\n",
       "      <td>-0.915931</td>\n",
       "      <td>-0.907524</td>\n",
       "      <td>-0.917612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-0.962169</td>\n",
       "      <td>-0.957125</td>\n",
       "      <td>-0.936108</td>\n",
       "      <td>-0.925179</td>\n",
       "      <td>-0.915931</td>\n",
       "      <td>-0.907524</td>\n",
       "      <td>-0.917612</td>\n",
       "      <td>-0.916772</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    var1(t-7)  var1(t-6)  var1(t-5)  var1(t-4)  var1(t-3)  var1(t-2)  \\\n",
       "7   -0.994956  -1.000000  -0.992434  -0.977301  -0.962169  -0.957125   \n",
       "8   -1.000000  -0.992434  -0.977301  -0.962169  -0.957125  -0.936108   \n",
       "9   -0.992434  -0.977301  -0.962169  -0.957125  -0.936108  -0.925179   \n",
       "10  -0.977301  -0.962169  -0.957125  -0.936108  -0.925179  -0.915931   \n",
       "11  -0.962169  -0.957125  -0.936108  -0.925179  -0.915931  -0.907524   \n",
       "\n",
       "    var1(t-1)   var1(t)  \n",
       "7   -0.936108 -0.925179  \n",
       "8   -0.925179 -0.915931  \n",
       "9   -0.915931 -0.907524  \n",
       "10  -0.907524 -0.917612  \n",
       "11  -0.917612 -0.916772  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PASOS=7\n",
    " \n",
    "# convertir serie temporal en datos de tipo supervisado\n",
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    intubados = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # secuencia (t-n, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(intubados.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast secuencia (t, t+1, ... t+n)\n",
    "    for i in range(0, n_out):\n",
    "        cols.append(intubados.shift(-i))\n",
    "        if i == 0:\n",
    "            names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "        else:\n",
    "            names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # quitar NaN \n",
    "    if dropnan:\n",
    "        agg.dropna(inplace=True)\n",
    "    return agg\n",
    " \n",
    "# load dataset\n",
    "values = intubados.values\n",
    "# todos los datos son float\n",
    "values = values.astype('float32')\n",
    "# normalizar de -1 a 1\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "values=values.reshape(-1, 1) # esto lo hacemos porque tenemos 1 sola dimension\n",
    "scaled = scaler.fit_transform(values)\n",
    "reframed = series_to_supervised(scaled, PASOS, 1)\n",
    "reframed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(432, 1, 7) (432,) (30, 1, 7) (30,)\n"
     ]
    }
   ],
   "source": [
    "# Dividir en train y test\n",
    "values = reframed.values\n",
    "n_train_days = 283+186 - (30+PASOS)\n",
    "train = values[:n_train_days, :]\n",
    "test = values[n_train_days:, :]\n",
    "# dividir en entradas y salidas\n",
    "x_train, y_train = train[:, :-1], train[:, -1]\n",
    "x_val, y_val = test[:, :-1], test[:, -1]\n",
    "# reshape entrada a 3 dimensiones [samples, timesteps, features]\n",
    "x_train = x_train.reshape((x_train.shape[0], 1, x_train.shape[1]))\n",
    "x_val = x_val.reshape((x_val.shape[0], 1, x_val.shape[1]))\n",
    "print(x_train.shape, y_train.shape, x_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Modelo. Secuencial, activaci√≥n tangente hiperb√≥lica, optimizador adam  \n",
    "def crear_modeloFF():\n",
    "    model = Sequential() \n",
    "    model.add(Dense(PASOS, input_shape=(1,PASOS),activation='tanh'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1, activation='tanh'))\n",
    "    model.compile(loss='mean_absolute_error',optimizer='Adam',metrics=[\"mse\"])\n",
    "    model.summary()\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 1, 7)              56        \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 7)                 0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 8         \n",
      "=================================================================\n",
      "Total params: 64\n",
      "Trainable params: 64\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From C:\\Users\\Fer\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 432 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "432/432 [==============================] - 0s 505us/step - loss: 0.5075 - mse: 0.4460 - val_loss: 0.4674 - val_mse: 0.2196\n",
      "Epoch 2/50\n",
      "432/432 [==============================] - 0s 180us/step - loss: 0.1156 - mse: 0.0293 - val_loss: 0.1531 - val_mse: 0.0242\n",
      "Epoch 3/50\n",
      "432/432 [==============================] - 0s 165us/step - loss: 0.0759 - mse: 0.0104 - val_loss: 0.1312 - val_mse: 0.0179\n",
      "Epoch 4/50\n",
      "432/432 [==============================] - 0s 143us/step - loss: 0.0682 - mse: 0.0083 - val_loss: 0.1249 - val_mse: 0.0162\n",
      "Epoch 5/50\n",
      "432/432 [==============================] - 0s 125us/step - loss: 0.0600 - mse: 0.0066 - val_loss: 0.0765 - val_mse: 0.0064\n",
      "Epoch 6/50\n",
      "432/432 [==============================] - 0s 132us/step - loss: 0.0529 - mse: 0.0051 - val_loss: 0.0920 - val_mse: 0.0089\n",
      "Epoch 7/50\n",
      "432/432 [==============================] - 0s 155us/step - loss: 0.0475 - mse: 0.0042 - val_loss: 0.0651 - val_mse: 0.0047\n",
      "Epoch 8/50\n",
      "432/432 [==============================] - 0s 127us/step - loss: 0.0424 - mse: 0.0035 - val_loss: 0.0482 - val_mse: 0.0027\n",
      "Epoch 9/50\n",
      "432/432 [==============================] - 0s 143us/step - loss: 0.0389 - mse: 0.0029 - val_loss: 0.0414 - val_mse: 0.0021\n",
      "Epoch 10/50\n",
      "432/432 [==============================] - 0s 133us/step - loss: 0.0359 - mse: 0.0025 - val_loss: 0.0364 - val_mse: 0.0016\n",
      "Epoch 11/50\n",
      "432/432 [==============================] - 0s 145us/step - loss: 0.0353 - mse: 0.0023 - val_loss: 0.0303 - val_mse: 0.0012\n",
      "Epoch 12/50\n",
      "432/432 [==============================] - 0s 126us/step - loss: 0.0335 - mse: 0.0021 - val_loss: 0.0159 - val_mse: 3.5836e-04\n",
      "Epoch 13/50\n",
      "432/432 [==============================] - 0s 141us/step - loss: 0.0328 - mse: 0.0020 - val_loss: 0.0180 - val_mse: 4.3129e-04\n",
      "Epoch 14/50\n",
      "432/432 [==============================] - 0s 143us/step - loss: 0.0320 - mse: 0.0019 - val_loss: 0.0208 - val_mse: 5.7731e-04\n",
      "Epoch 15/50\n",
      "432/432 [==============================] - 0s 151us/step - loss: 0.0315 - mse: 0.0019 - val_loss: 0.0170 - val_mse: 3.8733e-04\n",
      "Epoch 16/50\n",
      "432/432 [==============================] - 0s 120us/step - loss: 0.0314 - mse: 0.0019 - val_loss: 0.0158 - val_mse: 3.3945e-04\n",
      "Epoch 17/50\n",
      "432/432 [==============================] - 0s 136us/step - loss: 0.0315 - mse: 0.0019 - val_loss: 0.0253 - val_mse: 8.2715e-04\n",
      "Epoch 18/50\n",
      "432/432 [==============================] - 0s 128us/step - loss: 0.0306 - mse: 0.0018 - val_loss: 0.0186 - val_mse: 4.6838e-04\n",
      "Epoch 19/50\n",
      "432/432 [==============================] - 0s 124us/step - loss: 0.0306 - mse: 0.0018 - val_loss: 0.0153 - val_mse: 3.2022e-04\n",
      "Epoch 20/50\n",
      "432/432 [==============================] - 0s 141us/step - loss: 0.0309 - mse: 0.0018 - val_loss: 0.0214 - val_mse: 6.0297e-04\n",
      "Epoch 21/50\n",
      "432/432 [==============================] - 0s 136us/step - loss: 0.0304 - mse: 0.0018 - val_loss: 0.0196 - val_mse: 5.1845e-04\n",
      "Epoch 22/50\n",
      "432/432 [==============================] - 0s 138us/step - loss: 0.0304 - mse: 0.0017 - val_loss: 0.0168 - val_mse: 3.7979e-04\n",
      "Epoch 23/50\n",
      "432/432 [==============================] - 0s 136us/step - loss: 0.0306 - mse: 0.0017 - val_loss: 0.0262 - val_mse: 8.7822e-04\n",
      "Epoch 24/50\n",
      "432/432 [==============================] - 0s 148us/step - loss: 0.0301 - mse: 0.0017 - val_loss: 0.0245 - val_mse: 7.7741e-04\n",
      "Epoch 25/50\n",
      "432/432 [==============================] - 0s 137us/step - loss: 0.0298 - mse: 0.0017 - val_loss: 0.0163 - val_mse: 3.5786e-04\n",
      "Epoch 26/50\n",
      "432/432 [==============================] - 0s 145us/step - loss: 0.0294 - mse: 0.0016 - val_loss: 0.0143 - val_mse: 2.9047e-04\n",
      "Epoch 27/50\n",
      "432/432 [==============================] - 0s 146us/step - loss: 0.0312 - mse: 0.0018 - val_loss: 0.0143 - val_mse: 2.8516e-04\n",
      "Epoch 28/50\n",
      "432/432 [==============================] - 0s 143us/step - loss: 0.0298 - mse: 0.0017 - val_loss: 0.0143 - val_mse: 2.8033e-04\n",
      "Epoch 29/50\n",
      "432/432 [==============================] - 0s 136us/step - loss: 0.0295 - mse: 0.0016 - val_loss: 0.0149 - val_mse: 3.0490e-04\n",
      "Epoch 30/50\n",
      "432/432 [==============================] - 0s 132us/step - loss: 0.0292 - mse: 0.0016 - val_loss: 0.0142 - val_mse: 2.7700e-04\n",
      "Epoch 31/50\n",
      "432/432 [==============================] - 0s 128us/step - loss: 0.0295 - mse: 0.0016 - val_loss: 0.0171 - val_mse: 3.9649e-04\n",
      "Epoch 32/50\n",
      "432/432 [==============================] - 0s 136us/step - loss: 0.0294 - mse: 0.0016 - val_loss: 0.0153 - val_mse: 3.2081e-04\n",
      "Epoch 33/50\n",
      "432/432 [==============================] - 0s 126us/step - loss: 0.0292 - mse: 0.0016 - val_loss: 0.0255 - val_mse: 8.3398e-04\n",
      "Epoch 34/50\n",
      "432/432 [==============================] - 0s 139us/step - loss: 0.0290 - mse: 0.0016 - val_loss: 0.0187 - val_mse: 4.7634e-04\n",
      "Epoch 35/50\n",
      "432/432 [==============================] - 0s 145us/step - loss: 0.0287 - mse: 0.0016 - val_loss: 0.0150 - val_mse: 3.1101e-04\n",
      "Epoch 36/50\n",
      "432/432 [==============================] - 0s 134us/step - loss: 0.0287 - mse: 0.0016 - val_loss: 0.0177 - val_mse: 4.3023e-04\n",
      "Epoch 37/50\n",
      "432/432 [==============================] - 0s 131us/step - loss: 0.0287 - mse: 0.0016 - val_loss: 0.0148 - val_mse: 3.0052e-04\n",
      "Epoch 38/50\n",
      "432/432 [==============================] - 0s 143us/step - loss: 0.0287 - mse: 0.0016 - val_loss: 0.0175 - val_mse: 4.2186e-04\n",
      "Epoch 39/50\n",
      "432/432 [==============================] - 0s 142us/step - loss: 0.0287 - mse: 0.0015 - val_loss: 0.0221 - val_mse: 6.3643e-04\n",
      "Epoch 40/50\n",
      "432/432 [==============================] - 0s 134us/step - loss: 0.0286 - mse: 0.0015 - val_loss: 0.0163 - val_mse: 3.5674e-04\n",
      "Epoch 41/50\n",
      "432/432 [==============================] - 0s 134us/step - loss: 0.0280 - mse: 0.0015 - val_loss: 0.0172 - val_mse: 4.0491e-04\n",
      "Epoch 42/50\n",
      "432/432 [==============================] - 0s 132us/step - loss: 0.0287 - mse: 0.0016 - val_loss: 0.0145 - val_mse: 3.4277e-04\n",
      "Epoch 43/50\n",
      "432/432 [==============================] - 0s 126us/step - loss: 0.0282 - mse: 0.0015 - val_loss: 0.0192 - val_mse: 4.9211e-04\n",
      "Epoch 44/50\n",
      "432/432 [==============================] - 0s 122us/step - loss: 0.0283 - mse: 0.0015 - val_loss: 0.0229 - val_mse: 6.7941e-04\n",
      "Epoch 45/50\n",
      "432/432 [==============================] - 0s 139us/step - loss: 0.0287 - mse: 0.0015 - val_loss: 0.0173 - val_mse: 4.1112e-04\n",
      "Epoch 46/50\n",
      "432/432 [==============================] - 0s 132us/step - loss: 0.0278 - mse: 0.0015 - val_loss: 0.0141 - val_mse: 2.7556e-04\n",
      "Epoch 47/50\n",
      "432/432 [==============================] - 0s 126us/step - loss: 0.0278 - mse: 0.0015 - val_loss: 0.0164 - val_mse: 3.6455e-04\n",
      "Epoch 48/50\n",
      "432/432 [==============================] - 0s 112us/step - loss: 0.0275 - mse: 0.0015 - val_loss: 0.0141 - val_mse: 2.7281e-04\n",
      "Epoch 49/50\n",
      "432/432 [==============================] - 0s 125us/step - loss: 0.0273 - mse: 0.0014 - val_loss: 0.0209 - val_mse: 5.7279e-04\n",
      "Epoch 50/50\n",
      "432/432 [==============================] - 0s 127us/step - loss: 0.0277 - mse: 0.0015 - val_loss: 0.0151 - val_mse: 3.1034e-04\n"
     ]
    }
   ],
   "source": [
    "#entrenar el modelo\n",
    "EPOCHS=50\n",
    "\n",
    "model = crear_modeloFF()\n",
    "\n",
    "history=model.fit(x_train,y_train,epochs=EPOCHS,validation_data=(x_val,y_val),batch_size=PASOS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x648 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Validaci√≥n del modelo\n",
    "results=model.predict(x_val)\n",
    "plt.scatter(range(len(y_val)),y_val,c='g')\n",
    "plt.scatter(range(len(results)),results,c='r')\n",
    "plt.title('validate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fecha\n",
       "2021-07-01    2172\n",
       "2021-07-02    2187\n",
       "2021-07-03    1556\n",
       "2021-07-04    1027\n",
       "2021-07-05     593\n",
       "2021-06-22     291\n",
       "2021-06-23     285\n",
       "2021-06-24     306\n",
       "2021-06-25     315\n",
       "2021-06-26     320\n",
       "2021-06-27     321\n",
       "2021-06-28     324\n",
       "2021-06-29     337\n",
       "2021-06-30     361\n",
       "Name: intubados, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tomamos los √∫ltimos d√≠as\n",
    "ultimosDias = intubados['2021-06-22':'2021-07-05']\n",
    "ultimosDias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var1(t-7)</th>\n",
       "      <th>var1(t-6)</th>\n",
       "      <th>var1(t-5)</th>\n",
       "      <th>var1(t-4)</th>\n",
       "      <th>var1(t-3)</th>\n",
       "      <th>var1(t-2)</th>\n",
       "      <th>var1(t-1)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.984227</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.336488</td>\n",
       "      <td>-0.219769</td>\n",
       "      <td>-0.676130</td>\n",
       "      <td>-0.993691</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.336488</td>\n",
       "      <td>-0.219769</td>\n",
       "      <td>-0.676130</td>\n",
       "      <td>-0.993691</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.977918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.336488</td>\n",
       "      <td>-0.219769</td>\n",
       "      <td>-0.676130</td>\n",
       "      <td>-0.993691</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.977918</td>\n",
       "      <td>-0.968454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.219769</td>\n",
       "      <td>-0.676130</td>\n",
       "      <td>-0.993691</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.977918</td>\n",
       "      <td>-0.968454</td>\n",
       "      <td>-0.963197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-0.676130</td>\n",
       "      <td>-0.993691</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.977918</td>\n",
       "      <td>-0.968454</td>\n",
       "      <td>-0.963197</td>\n",
       "      <td>-0.962145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-0.993691</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.977918</td>\n",
       "      <td>-0.968454</td>\n",
       "      <td>-0.963197</td>\n",
       "      <td>-0.962145</td>\n",
       "      <td>-0.958991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.977918</td>\n",
       "      <td>-0.968454</td>\n",
       "      <td>-0.963197</td>\n",
       "      <td>-0.962145</td>\n",
       "      <td>-0.958991</td>\n",
       "      <td>-0.945321</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    var1(t-7)  var1(t-6)  var1(t-5)  var1(t-4)  var1(t-3)  var1(t-2)  \\\n",
       "7    0.984227   1.000000   0.336488  -0.219769  -0.676130  -0.993691   \n",
       "8    1.000000   0.336488  -0.219769  -0.676130  -0.993691  -1.000000   \n",
       "9    0.336488  -0.219769  -0.676130  -0.993691  -1.000000  -0.977918   \n",
       "10  -0.219769  -0.676130  -0.993691  -1.000000  -0.977918  -0.968454   \n",
       "11  -0.676130  -0.993691  -1.000000  -0.977918  -0.968454  -0.963197   \n",
       "12  -0.993691  -1.000000  -0.977918  -0.968454  -0.963197  -0.962145   \n",
       "13  -1.000000  -0.977918  -0.968454  -0.963197  -0.962145  -0.958991   \n",
       "\n",
       "    var1(t-1)  \n",
       "7   -1.000000  \n",
       "8   -0.977918  \n",
       "9   -0.968454  \n",
       "10  -0.963197  \n",
       "11  -0.962145  \n",
       "12  -0.958991  \n",
       "13  -0.945321  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Volver a procesar los datos\n",
    "values = ultimosDias.values\n",
    "values = values.astype('float32')\n",
    "# Normalizar\n",
    "values=values.reshape(-1, 1) # esto lo hacemos porque tenemos 1 sola dimension\n",
    "scaled = scaler.fit_transform(values)\n",
    "reframed = series_to_supervised(scaled, PASOS, 1)\n",
    "reframed.drop(reframed.columns[[7]], axis=1, inplace=True)\n",
    "reframed.head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-1.        , -0.97791797, -0.96845424, -0.96319664,\n",
       "         -0.9621451 , -0.9589906 , -0.9453207 ]]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Convertir a array la √∫ltima semana\n",
    "values = reframed.values\n",
    "x_test = values[6:, :]\n",
    "x_test = x_test.reshape((x_test.shape[0], 1, x_test.shape[1]))\n",
    "x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[-1.         -0.97791797 -0.96845424 -0.96319664 -0.9621451\n",
      "   -0.9589906  -0.9453207 ]]]\n",
      "[[[-0.97791797 -0.96845424 -0.96319664 -0.9621451  -0.9589906\n",
      "   -0.9453207  -0.8560839 ]]]\n",
      "[[[-0.96845424 -0.96319664 -0.9621451  -0.9589906  -0.9453207\n",
      "   -0.8560839  -0.8361746 ]]]\n",
      "[[[-0.96319664 -0.9621451  -0.9589906  -0.9453207  -0.8560839\n",
      "   -0.8361746  -0.8037949 ]]]\n",
      "[[[-0.9621451 -0.9589906 -0.9453207 -0.8560839 -0.8361746 -0.8037949\n",
      "   -0.785542 ]]]\n",
      "[[[-0.9589906  -0.9453207  -0.8560839  -0.8361746  -0.8037949\n",
      "   -0.785542   -0.77458435]]]\n",
      "[[[-0.9453207  -0.8560839  -0.8361746  -0.8037949  -0.785542\n",
      "   -0.77458435 -0.7577111 ]]]\n"
     ]
    }
   ],
   "source": [
    "#Predicci√≥n\n",
    "def agregarNuevoValor(x_test,nuevoValor):\n",
    "    for i in range(x_test.shape[2]-1):\n",
    "        x_test[0][0][i] = x_test[0][0][i+1]\n",
    "    x_test[0][0][x_test.shape[2]-1]=nuevoValor\n",
    "    return x_test\n",
    "\n",
    "results=[]\n",
    "for i in range(7):\n",
    "    parcial=model.predict(x_test)\n",
    "    results.append(parcial[0])\n",
    "    print(x_test)\n",
    "    x_test=agregarNuevoValor(x_test,parcial[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[421.86418863],\n",
       "       [440.79795512],\n",
       "       [471.59103896],\n",
       "       [488.94955654],\n",
       "       [499.37029013],\n",
       "       [515.41674269],\n",
       "       [510.35826072]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Imprimir predicci√≥n de la siguiente semana\n",
    "adimen = [x for x in results]    \n",
    "inverted = scaler.inverse_transform(adimen)\n",
    "inverted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
